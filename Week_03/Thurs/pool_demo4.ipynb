{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "# Using a pool of workers\n",
    "<hr/>\n",
    "\n",
    "In many situations we have J jobs to do and P processors available.  If each job takes $T_j$ time, it would helpful to have an automated procedure for launching jobs on processes in such a way that each process uses approximately $W_p$ total work, where\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mbox{total work per processor} \\qquad W_p \\approx \\frac{1}{P}\\sum_{j=1}^J T_j \\qquad p = 1,2,...,P\n",
    "\\end{equation*}\n",
    "\n",
    "The `multiprocessing` module's Pool object solves this problem.   \n",
    "\n",
    "If we have several jobs which we expect to take unequal lengths of time to process, we can use a *pool* of workers.  The advantage of this approach is that the processes will be automatically launched, and results automatically collected and returned.  The steps in launching a pool are as follows : \n",
    "\n",
    "1.  Decide on how many *tasks* should be launched (`njobs`)\n",
    "\n",
    "2.  Decide on how many *processes* should be launched (`nprocs`)\n",
    "\n",
    "3.  Define functions that should be called when defining a worker process or processes (`worker`).  \n",
    "\n",
    "4.  Launch the pool of workers.  There are two conceptual ways to launch jobs:\n",
    "\n",
    "    * Use `apply` or `apply_async`.  This will launch a single job, with a single argument, using a process from the pool.   Multiple processes can be launched with multiple calls to `apply`.  \n",
    "    \n",
    "    * Use `map` or `map_async`.  This will launch multiple jobs to run the same task on an  *iterable* object (array, list, zip object, and so on).  \n",
    "    \n",
    "Here are four sample codes.  The function to be applied in each case is `f`, with an array of `njobs` tuples `data`.  In each case, the Pool is defined as\n",
    "<pre><code>\n",
    "pool = multiprocessing.Pool(processes=nprocs)\n",
    "</code></pre>\n",
    "\n",
    "Chunksize (illustrated in Example 5) is set to 1 by default.  For asynchronous calls, we can also specify a callback that will process results as they become available.\n",
    "\n",
    "For all examples, the results from all processes are stored in `results`. \n",
    "\n",
    "<hr/>\n",
    "\n",
    "### Blocking code using `Pool.map`\n",
    "\n",
    "<pre><code>\n",
    "# Blocks until all results are ready\n",
    "results = pool.map(func=f, iterable=data)\n",
    "</code></pre>\n",
    "\n",
    "<hr/>\n",
    "\n",
    "### Non-blocking code using `Pool.map_async`\n",
    "Results can be processed as they become available using a `callback` function.\n",
    "\n",
    "<pre><code>\n",
    "# Non-blocking code.  Results can be processed by a callback.\n",
    "async_results = pool.map_async(func=f, iterable=data, \n",
    "    callback=cb)\n",
    "\n",
    "# Blocks until results are ready\n",
    "results = async_results.get()    \n",
    "</code></pre>\n",
    "\n",
    "<hr/>\n",
    "\n",
    "### Blocking code using `Pool.apply`\n",
    "Code will run sequentially - probably not what we want for parallel computing!\n",
    "<html><pre><code>\n",
    "results = []\n",
    "for d in data:\n",
    "    # Blocks until job is done\n",
    "    r = pool.apply(func=worker, args=(d,))        \n",
    "    results.append(r)\n",
    "</code></pre></html>\n",
    "\n",
    "<hr/>\n",
    "\n",
    "### Non-blocking code using `Pool.apply_async`\n",
    "We can use a `callback` to process the results as they become available.\n",
    "<pre><code>\n",
    "async_results = []\n",
    "for d in data:\n",
    "    # Non-blocking calls\n",
    "    r = pool.apply_async(func=f,args=(d,),callback=cb)\n",
    "    async_results.append(r)\n",
    "    \n",
    "# Blocks until results are ready \n",
    "results = [r.get() for r in async_results] \n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "## Results explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code that follows, we provide several examples illustrating each of the above modes for calling a Pool of workers. \n",
    "\n",
    "The following are typical results obtained using the `Pool.map_async` call.\n",
    "<pre><code>\n",
    "Launching 19 jobs on 8 cores\n",
    "In process 4916 ( 0) is sleeping   4.8323 seconds\n",
    "In process 4918 ( 2) is sleeping   0.0375 seconds\n",
    "In process 4921 ( 5) is sleeping   2.9111 seconds\n",
    "In process 4917 ( 1) is sleeping   2.2037 seconds\n",
    "In process 4922 ( 6) is sleeping   3.3578 seconds\n",
    "In process 4920 ( 4) is sleeping   4.6963 seconds\n",
    "In process 4919 ( 3) is sleeping   4.5549 seconds\n",
    "In process 4923 ( 7) is sleeping   0.4197 seconds\n",
    "In process 4918 ( 8) is sleeping   3.8324 seconds\n",
    "In process 4923 ( 9) is sleeping   1.1840 seconds\n",
    "In process 4923 (10) is sleeping   0.1541 seconds\n",
    "In process 4923 (11) is sleeping   3.9439 seconds\n",
    "In process 4917 (12) is sleeping   1.7304 seconds\n",
    "In process 4921 (13) is sleeping   3.1164 seconds\n",
    "In process 4922 (14) is sleeping   3.0791 seconds\n",
    "In process 4918 (15) is sleeping   0.7428 seconds\n",
    "In process 4917 (16) is sleeping   0.9155 seconds\n",
    "In process 4919 (17) is sleeping   0.5721 seconds\n",
    "In process 4918 (18) is sleeping   0.0731 seconds\n",
    "<br/>\n",
    "Total time spent in each process\n",
    "Process  1 (4916)    4.8323(s)    1 job(s) (0,)\n",
    "Process  2 (4917)    4.8496(s)    3 job(s) (1, 12, 16)\n",
    "Process  3 (4918)    4.6857(s)    4 job(s) (2, 8, 15, 18)\n",
    "Process  4 (4919)    5.1269(s)    2 job(s) (3, 17)\n",
    "Process  5 (4920)    4.6963(s)    1 job(s) (4,)\n",
    "Process  6 (4921)    6.0275(s)    2 job(s) (5, 13)\n",
    "Process  7 (4922)    6.4369(s)    2 job(s) (6, 14)\n",
    "Process  8 (4923)    5.7017(s)    4 job(s) (7, 9, 10, 11)\n",
    "\n",
    "      Total work done (s)      42.3570\n",
    "      Wall clock time (s)       6.4890\n",
    "</code></pre>\n",
    "The first set of results (19 lines) is printed for each job launched and \n",
    "provides the process PID (decided by the OS), the task number (0-18), and the time spent in each job.   This information is printed as jobs are launched. \n",
    "\n",
    "The second set of results (8 lines) collects process information and provides the processor number (1-8) and PID, the total time spent in that process, the number of jobs launched on that processor, and the job numbers launched on that processor.\n",
    "\n",
    "**Observations.** The first set of results (first 19 lines) are printed as jobs are launched and illustrates the `asynchronous` nature of the call.  Jobs do not necessarily start processing as soon as they are launched.  For example, jobs 2 and 5 are started before job 1.  On the other hand, if we were to sort this list on job number, we would see that jobs are launched on our 8 processors in order.  Here are the first several jobs taken from the top of a list sorted on job number. \n",
    "\n",
    "<pre><code>\n",
    "In process 4916 ( 0) is sleeping   4.8323 seconds\n",
    "In process 4917 ( 1) is sleeping   2.2037 seconds\n",
    "In process 4918 ( 2) is sleeping   0.0375 seconds\n",
    "In process 4919 ( 3) is sleeping   4.5549 seconds\n",
    "In process 4920 ( 4) is sleeping   4.6963 seconds\n",
    "In process 4921 ( 5) is sleeping   2.9111 seconds\n",
    "In process 4922 ( 6) is sleeping   3.3578 seconds\n",
    "In process 4923 ( 7) is sleeping   0.4197 seconds\n",
    "In process 4918 ( 8) is sleeping   3.8324 seconds\n",
    "In process 4923 ( 9) is sleeping   1.1840 seconds\n",
    "....\n",
    "</code></pre>\n",
    "The first 8 jobs (jobnums 0-7) are launched in order on processors 4916-4923, but the 9th job (jobnum=8) is launched on process 4918, the first processor available (jobs on 4916 and 4917 were still processing).  Similarly, job 10 (jobnum=9) is launched on the next avalailable processor 4923.\n",
    "\n",
    "Post-processing the results (second 8 lines), we see that to achieve approximately the same amount of time per processor (i.e. *load balancing*), jobs are distributed unequally.  To achieve an approximate time of 5s per process, processors 1 and 5 were only able to processs 1 job, whereas processors 3 and 8 were able to process 4 jobs each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "## Python modules used for all examples\n",
    "\n",
    "The following creates and saves the module `pool_tools.py`, used by all example.   The magic command `%%file` creates the indicated file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file pool_tools.py\n",
    "from multiprocessing import Pool\n",
    "import time, os, random\n",
    "\n",
    "def worker(z):\n",
    "    jobnum, t = z    # Distribute tuple to variables.\n",
    "    id = os.getpid()\n",
    "    print(\"In process {} ({:2d}) is sleeping {:8.4f} seconds\".format(id,jobnum,t))\n",
    "    time.sleep(t)\n",
    "    return (jobnum,t,os.getpid())\n",
    "\n",
    "def print_pool_results(res,np):\n",
    "    # how much time was spent in each process? \n",
    "    pids = sorted(set([z[2] for z in res]))    # Get a unique set of PIDs\n",
    "    print(\"\")\n",
    "    print(\"Total time spent in each process\")\n",
    "    total_time = 0\n",
    "    for i,p in enumerate(pids):\n",
    "        proc_count = sum([1 for z in res if z[2] == p])\n",
    "        proc_time  = sum([z[1] for z in res if z[2] == p])\n",
    "        proc_jobs  = tuple([z[0] for z in res if z[2] == p])\n",
    "        print(\"Process {:2d} ({})  {:8.4f}(s) {:4d} job(s) {}\"\n",
    "              .format(i+1,p,proc_time,proc_count,proc_jobs))\n",
    "        total_time += proc_time\n",
    "    print(\"\")\n",
    "    print(\"{:>25s} {:12.4f}\".format(\"Total work done (s)\",total_time))                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "## Example 1 : pool.map(func=f,iterable=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pool_tools import *\n",
    "\n",
    "def test1(data,np):\n",
    "    pool = Pool(processes=np)              \n",
    "\n",
    "    # This function blocks until results 'res' are available\n",
    "    results = pool.map(func=worker,iterable=data)\n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [5*random.random() for i in range(njobs)]\n",
    "data = zip(range(njobs),sleep_times)    # Create list of tuples (p,t)\n",
    "    \n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test1(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "## Example 2 : pool.map_async(func=f,iterable=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pool_tools import *\n",
    "\n",
    "def test2(data,np):\n",
    "    pool = Pool(processes=np)              \n",
    "    \n",
    "    # This is non-blocking\n",
    "    async_results = pool.map_async(func=worker,iterable=data)\n",
    "    \n",
    "    # This call blocks until all results are available\n",
    "    results = async_results.get()   \n",
    "    \n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [5*random.random() for i in range(njobs)]\n",
    "data = zip(range(njobs),sleep_times)    # Create list of tuples (p,t)\n",
    "    \n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test2(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "## Example 3 : pool.apply(func = f,args = data)\n",
    "\n",
    "Using this mode, jobs are launched in order and run sequentially.  Jobs are not run in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pool_tools import *\n",
    "\n",
    "def test3(data,np):\n",
    "    pool = Pool(processes=np)          \n",
    "\n",
    "    results = []\n",
    "    for d in data:\n",
    "        # This call is blocking;  jobs run sequentially\n",
    "        r = pool.apply(worker,args=(d,))\n",
    "        results.append(r)\n",
    "    \n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [5*random.random() for i in range(njobs)]\n",
    "pnum = range(njobs)\n",
    "data = zip(pnum,sleep_times)\n",
    "    \n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test3(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "## Example 4 : pool.apply_async(func=data,args=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pool_tools import *\n",
    "\n",
    "def test4(data,np):\n",
    "    pool = Pool(processes=np)             \n",
    "\n",
    "    # This call is non-blocking;  \n",
    "    async_results = []\n",
    "    for d in data:\n",
    "        r = pool.apply_async(worker,args = (d,))\n",
    "        async_results.append(r)\n",
    "    pool.close()\n",
    "    pool.join()     # Block here or with r.get() below\n",
    "    results = [r.get() for r in async_results]  # this blocks if pool is not closed/joined\n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [5*random.random() for i in range(njobs)]\n",
    "pnum = range(njobs)\n",
    "data = zip(pnum,sleep_times)\n",
    "    \n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test4(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "## Example 5 : Controlling how tasks are distributed\n",
    "\n",
    "We can have some control over how tasks are handed off to processors using the `chunksize` keyword.  Setting `chunksize=4` when calling `map_async` for example, the pool will put the first four tasks on the first processor, the second four tasks on the second processor, and so on.  \n",
    "\n",
    "There are two main drawbacks to this approach : \n",
    "\n",
    "* This can lead to very bad load balancing.\n",
    "* Some processors in the pool may not get used at all.\n",
    "\n",
    "In the following example, we create 23 tasks for 8 processors, with a chunksize of 4.  With this configuration, 5 processors will get 4 tasks each, 1 processor will get 3 tasks, and 2 processors will remain idle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pool_tools import  *\n",
    "\n",
    "def test5(data,np):\n",
    "    pool = Pool(processes=np)              \n",
    "\n",
    "    # This function blocks until results 'res' are available\n",
    "    async_results = pool.map_async(func=worker,iterable=data,chunksize=4)\n",
    "    results = async_results.get()\n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [5*random.random() for i in range(njobs)]\n",
    "data = zip(range(njobs),sleep_times)    # Create list of tuples (p,t)\n",
    "    \n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test5(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "## Example 6 : Using a callback to process results\n",
    "\n",
    "In this example, we use a callback to process results as they become available.  Notice that results are available even before all jobs have been launched.  Also in this example, we illustrate the idea that the main program can be doing work while we are waiting for all jobs to complete. \n",
    "\n",
    "The callback takes the result returned from our worker process and computes both the total job time (`rt`) taken so far, and total wall-clock (`wc`) time.  Since we are running on multiple processors, we expect `rt` $>$ `wc`. \n",
    "\n",
    "**Note:**  For this example, we have increased the time spent in each process to some value in $[0,30]$ (rather than $[0,5]$ in previous examples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pool_tools import *\n",
    "\n",
    "# Process results right away.\n",
    "running_total = 0\n",
    "def cb(res):\n",
    "    global t0, running_total\n",
    "    r = res\n",
    "    t1 = time.time()\n",
    "    wc = t1-t0\n",
    "    running_total += r[1]\n",
    "    print(\"Process {}, job {:2d} is done in {:8.4f} (s) (wc/rt {:8.2f}/{:.2f})\".\n",
    "          format(r[2],r[0],r[1],wc,running_total))\n",
    "\n",
    "def test6(data,np):\n",
    "    pool = Pool(processes=np)              # start 4 worker processes\n",
    "\n",
    "    # This call is non-blocking;  \n",
    "    async_results = []\n",
    "    for d in data:\n",
    "        r = pool.apply_async(func=worker, args=(d,), callback=cb)\n",
    "        async_results.append(r)\n",
    "    pool.close()\n",
    "    print(\"---> Do some useful work while we are waiting for background jobs.\")\n",
    "    time.sleep(25)\n",
    "    print(\"---> Done with our other work !!!\")\n",
    "    pool.join()     # Block here or with r.get() below\n",
    "    results = [r.get() for r in async_results]  # this blocks if pool is not closed/joined\n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [30*random.random() for i in range(njobs)]\n",
    "pnum = range(njobs)\n",
    "data = zip(pnum,sleep_times)\n",
    "    \n",
    "t0 = time.time()\n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test6(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
